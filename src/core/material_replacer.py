"""
æè´¨æ›¿æ¢æ ¸å¿ƒæ¨¡å—

åŸºäºè®¾è®¡æ–‡æ¡£V3å®ç°ï¼š
- Phase 1: Step1/Step2/Step3 ä¸‰æ­¥åŒ¹é…
- Phase 2: æœ€å°ä¸´è¿‘æ”¹åŠ¨ï¼ˆå±€éƒ¨ swap/shiftï¼‰
- Phase 3: å…¨å±€é¡ºåºæ£€æŸ¥ä¸äºŒæ¬¡ä¿®å¤

çº¦æŸï¼šæºé¡ºåºè‡³ä¸Šï¼Œå¯¼å‡ºä¸é˜»æ­¢
"""

from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Tuple
from enum import Enum
import re
import logging

logger = logging.getLogger(__name__)

# ä½¿ç”¨ sampler_type_parser ä¸­çš„ç»Ÿä¸€è§£æå‡½æ•°ï¼ˆéœ€è¦åœ¨ Sampler ç±»ä¹‹å‰å¯¼å…¥ï¼‰
from .sampler_type_parser import parse_sampler_type


class MatchStatus(Enum):
    """åŒ¹é…çŠ¶æ€æšä¸¾"""
    PERFECT_MATCH = 'PERFECT_MATCH'      # ğŸŸ¢ åºå·+ç±»å‹å®Œç¾åŒ¹é…
    ADJACENT_MATCH = 'ADJACENT_MATCH'    # ğŸŸ¡ ç±»å‹åŒ¹é…ä½†åºå·ä¸åŒ
    UNMATCHED = 'UNMATCHED'              # ğŸ”´ æºé‡‡æ ·å™¨æ— æ³•åŒ¹é…
    UNCOVERED = 'UNCOVERED'              # ğŸ”µ ç›®æ ‡åŸæœ‰è·¯å¾„æœªè¢«è¦†ç›–
    EMPTY = 'EMPTY'                      # âšª ç›®æ ‡ç©ºé‡‡æ ·å™¨æœªè¢«å¡«å……


# çŠ¶æ€å›¾æ ‡ï¼ˆä¸éœ€è¦ç¿»è¯‘ï¼‰
STATUS_ICONS = {
    MatchStatus.PERFECT_MATCH: 'ğŸŸ¢',
    MatchStatus.ADJACENT_MATCH: 'ğŸŸ¡',
    MatchStatus.UNMATCHED: 'ğŸ”´',
    MatchStatus.UNCOVERED: 'ğŸ”µ',
    MatchStatus.EMPTY: 'âšª',
}


@dataclass
class ConversionOptions:
    """è½¬æ¢é€‰é¡¹é…ç½®"""
    # === è·¯å¾„å¤„ç†é€‰é¡¹ ===
    simplify_texture_path: bool = False    # ç®€åŒ–è´´å›¾è·¯å¾„
    simplify_material_path: bool = False   # ç®€åŒ–æè´¨è·¯å¾„
    
    # === å‚æ•°è¿ç§»é€‰é¡¹ ===
    migrate_parameters: bool = True        # è¿ç§»æºæè´¨å‚æ•°
    
    # === åŒ¹é…ç­–ç•¥é€‰é¡¹ ===
    prefer_perfect_match: bool = True      # ä¼˜å…ˆå®Œç¾åŒ¹é…
    prefer_marked_coverage: bool = True    # ä¼˜å…ˆè¦†ç›–æ ‡è®°é‡‡æ ·å™¨
    allow_order_adjustment: bool = True    # å…è®¸é¡ºåºè°ƒæ•´
    max_order_adjustments: int = 3         # æœ€å¤§é¡ºåºè°ƒæ•´æ•°é‡
    strict_order_validation: bool = True   # é¡ºåºæ ¡éªŒï¼ˆä»…æç¤ºï¼Œä¸é˜»æ­¢å¯¼å‡ºï¼‰


@dataclass
class Sampler:
    """é‡‡æ ·å™¨æ•°æ®ç»“æ„"""
    type_name: str          # é‡‡æ ·å™¨ç±»å‹åï¼ˆå¦‚ C_DetailBlend_Rich__snp_Texture2D_7_AlbedoMapï¼‰
    path: str = ""          # è´´å›¾è·¯å¾„
    scale_x: float = 1.0
    scale_y: float = 1.0
    unk10: int = 0
    unk11: bool = False
    unk14: int = 0
    unk18: int = 0
    unk1c: int = 0
    
    # è§£æåçš„ä¿¡æ¯
    index: int = -1         # åºå·ï¼ˆå¦‚ 7ï¼‰
    base_type: str = ""     # åŸºç¡€ç±»å‹ï¼ˆå¦‚ AlbedoMapï¼‰
    is_legacy: bool = False # æ˜¯å¦ä¸ºæ—§ç‰ˆæ ¼å¼ï¼ˆg_DiffuseTextureç­‰ï¼‰
    sorted_pos: int = 0     # æ’åºä½ç½®
    
    @property
    def has_path(self) -> bool:
        """æ˜¯å¦ä¸ºæ ‡è®°é‡‡æ ·å™¨ï¼ˆPathéç©ºï¼‰"""
        return bool(self.path and self.path.strip())
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any], sorted_pos: int = 0) -> 'Sampler':
        """ä»JSONå­—å…¸åˆ›å»ºSampler"""
        sampler = cls(
            type_name=data.get('Type', ''),
            path=data.get('Path', ''),
            scale_x=data.get('Scale', {}).get('X', 1.0),
            scale_y=data.get('Scale', {}).get('Y', 1.0),
            unk10=data.get('Unk10', 0),
            unk11=data.get('Unk11', False),
            unk14=data.get('Unk14', 0),
            unk18=data.get('Unk18', 0),
            unk1c=data.get('Unk1C', 0),
            sorted_pos=sorted_pos,
        )
        sampler.index, sampler.base_type, sampler.is_legacy = parse_sampler_type(sampler.type_name)
        return sampler
    
    def to_dict(self) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºJSONå­—å…¸"""
        return {
            'Type': self.type_name,
            'Path': self.path,
            'Scale': {'X': self.scale_x, 'Y': self.scale_y},
            'Unk10': self.unk10,
            'Unk11': self.unk11,
            'Unk14': self.unk14,
            'Unk18': self.unk18,
            'Unk1C': self.unk1c,
        }


@dataclass
class Material:
    """æè´¨æ•°æ®ç»“æ„"""
    name: str
    mtd_path: str
    samplers: List[Sampler]
    gx_index: int = 0
    index: int = 0
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'Material':
        """ä»JSONå­—å…¸åˆ›å»ºMaterial"""
        textures = data.get('Textures', [])
        samplers = [Sampler.from_dict(t, i) for i, t in enumerate(textures)]
        return cls(
            name=data.get('Name', ''),
            mtd_path=data.get('MTD', ''),
            samplers=samplers,
            gx_index=data.get('GXIndex', 0),
            index=data.get('Index', 0),
        )
    
    def to_dict(self) -> Dict[str, Any]:
        """å¯¼å‡ºä¸ºJSONå­—å…¸"""
        return {
            'Name': self.name,
            'MTD': self.mtd_path,
            'Textures': [s.to_dict() for s in self.samplers],
            'GXIndex': self.gx_index,
            'Index': self.index,
        }


@dataclass
class MatchResult:
    """å•ä¸ªé‡‡æ ·å™¨çš„åŒ¹é…ç»“æœ"""
    source_pos: int                     # æºé‡‡æ ·å™¨ä½ç½®
    target_pos: Optional[int]           # ç›®æ ‡é‡‡æ ·å™¨ä½ç½®ï¼ˆNoneè¡¨ç¤ºæœªåŒ¹é…ï¼‰
    status: MatchStatus                 # åŒ¹é…çŠ¶æ€
    reason: str = ""                    # åŸå› è¯´æ˜
    order_adjusted: bool = False        # æ˜¯å¦å‘ç”Ÿäº†é¡ºåºè°ƒæ•´
    adjustment_detail: str = ""         # è°ƒæ•´è¯¦æƒ…


@dataclass
class ReplaceResult:
    """æè´¨æ›¿æ¢ç»“æœ"""
    source_material: Material
    target_material: Material
    results: List[MatchResult]          # æŒ‰æºé‡‡æ ·å™¨é¡ºåºæ’åˆ—
    warnings: List[str] = field(default_factory=list)
    order_adjustments_count: int = 0
    global_repair_triggered: bool = False



class MaterialReplacer:
    """æè´¨æ›¿æ¢å™¨"""
    
    def __init__(self, options: Optional[ConversionOptions] = None):
        self.options = options or ConversionOptions()
        self._adjustment_count = 0
    
    def replace(self, source: Material, target: Material) -> ReplaceResult:
        """
        æ‰§è¡Œæè´¨æ›¿æ¢ - Sort-Match-Restore æ¡†æ¶
        
        åŒ¹é…ç­–ç•¥ï¼š
        1. æºæè´¨ï¼šåªæœ‰æœ‰è·¯å¾„çš„é‡‡æ ·å™¨å‚ä¸åŒ¹é…ï¼ŒæŒ‰ Index æ’åºï¼ˆå†³å®šåŠ è½½é¡ºåºï¼‰
        2. ç›®æ ‡æè´¨ï¼šæ‰€æœ‰é‡‡æ ·å™¨æŒ‰ Index æ’åºï¼Œä½œä¸ºåŒ¹é…å€™é€‰
        3. æ¯æ¬¡ä»å¤´æœç´¢ï¼Œæ—  cursor é™åˆ¶
        4. å†²çªæ—¶è¿›è¡Œå¯¹æ¯”åˆ†æ
        5. Phase 2/3 è°ƒç”¨é“¾å¯ç”¨
        
        æ—§ç‰ˆæè´¨æ£€æµ‹ï¼š
        - å¦‚æœæºæè´¨åŒ…å«æ—§ç‰ˆé‡‡æ ·å™¨ï¼ˆg_xxxæ ¼å¼ï¼‰ï¼Œä½¿ç”¨ç‹¬ç«‹çš„åŒ¹é…é€»è¾‘
        - æ—§ç‰ˆåŒ¹é…ç‹¬ç«‹äºæ ¸å¿ƒåŒ¹é…æœºåˆ¶ï¼Œä¸å½±å“ç°æœ‰é€»è¾‘
        """
        self._adjustment_count = 0
        self._log_lines: List[str] = []
        warnings: List[str] = []
        
        # === æ—§ç‰ˆæè´¨æ£€æµ‹ ===
        # æ£€æµ‹æºæè´¨ä¸­æ˜¯å¦æœ‰æ—§ç‰ˆé‡‡æ ·å™¨ï¼ˆis_legacy=True ä¸”æœ‰è·¯å¾„ï¼‰
        source_legacy_samplers = [s for s in source.samplers if s.is_legacy and s.has_path]
        
        if source_legacy_samplers:
            # æ£€æµ‹ç›®æ ‡æè´¨ç±»å‹
            target_has_modern = any(not s.is_legacy and s.index >= 0 for s in target.samplers)
            target_has_legacy = any(s.is_legacy for s in target.samplers)
            
            self._log_lines.append(f"[Legacy Detection] Source has {len(source_legacy_samplers)} legacy samplers")
            self._log_lines.append(f"[Legacy Detection] Target has modern: {target_has_modern}, legacy: {target_has_legacy}")
            
            # ä½¿ç”¨ç‹¬ç«‹çš„æ—§ç‰ˆåŒ¹é…é€»è¾‘
            return self._replace_legacy(source, target, source_legacy_samplers, target_has_modern)
        
        # === Phase 0: Sortï¼ˆé¢„å¤„ç†æ’åºï¼‰===
        
        # æºæè´¨ï¼šç­›é€‰æœ‰è·¯å¾„çš„é‡‡æ ·å™¨ï¼ŒæŒ‰ Index æ’åº
        source_with_path = [(i, s) for i, s in enumerate(source.samplers) if s.has_path]
        sorted_source = sorted(source_with_path, key=lambda x: (x[1].index, x[0]))
        
        # ç›®æ ‡æè´¨ï¼šæ‰€æœ‰é‡‡æ ·å™¨æŒ‰ Index æ’åº
        indexed_target = list(enumerate(target.samplers))
        sorted_target = sorted(indexed_target, key=lambda x: (x[1].index, x[0]))
        
        self._log_lines.append(f"[Phase0] Source with path: {len(sorted_source)}, Target: {len(sorted_target)}")
        self._log_lines.append(f"[Phase0] Source indices: {[s[1].index for s in sorted_source]}")
        self._log_lines.append(f"[Phase0] Target indices: {[t[1].index for t in sorted_target]}")
        
        # åˆå§‹åŒ–çŠ¶æ€
        occupied = [False] * len(sorted_target)
        match_of_target: Dict[int, int] = {}  # sorted_target_idx -> sorted_source_idx
        
        # ç»“æœåˆ—è¡¨
        sorted_results: List[MatchResult] = []
        
        # === Phase 1: Matchï¼ˆä½¿ç”¨ _match_single_samplerï¼‰===
        for sorted_src_idx, (orig_src_pos, src_sampler) in enumerate(sorted_source):
            # ä½¿ç”¨ _match_single_samplerï¼ˆä»å¤´æœç´¢ï¼Œæ—  cursorï¼‰
            result = self._match_single_sampler(
                sorted_src_idx, orig_src_pos, src_sampler,
                sorted_target, occupied, match_of_target
            )
            
            sorted_target_idx = result.target_pos
            
            # å¤„ç†åŒ¹é…ç»“æœ
            if sorted_target_idx is not None:
                # è½¬æ¢ä¸ºåŸå§‹ç›®æ ‡ä½ç½®
                result.target_pos = sorted_target[sorted_target_idx][0]
                occupied[sorted_target_idx] = True
                match_of_target[sorted_target_idx] = sorted_src_idx
            
            sorted_results.append(result)
            
            self._log_lines.append(
                f"[Match] Src[{orig_src_pos}] idx={src_sampler.index} ({src_sampler.base_type}) -> "
                f"Target orig={result.target_pos} [{result.status.name}]"
            )
        
        # === Restore: è¿˜åŸåˆ°åŸå§‹é¡ºåº ===
        results: List[MatchResult] = []
        sorted_result_map = {r.source_pos: r for r in sorted_results}
        
        for src_pos, src_sampler in enumerate(source.samplers):
            if src_pos in sorted_result_map:
                results.append(sorted_result_map[src_pos])
            else:
                # æºé‡‡æ ·å™¨æ— è·¯å¾„ï¼Œæ ‡è®°ä¸º EMPTY
                results.append(MatchResult(
                    source_pos=src_pos,
                    target_pos=None,
                    status=MatchStatus.EMPTY,
                    reason="æºé‡‡æ ·å™¨æ— è·¯å¾„ï¼Œè·³è¿‡åŒ¹é…",
                ))
        
        # === Phase 3: å…¨å±€é¡ºåºæ£€æŸ¥ ===
        if self.options.strict_order_validation:
            repair_triggered = self._global_order_check_and_repair(
                source.samplers, target.samplers, results,
                [False] * len(target.samplers), {}
            )
            if repair_triggered:
                warnings.append("è§¦å‘å…¨å±€é¡ºåºä¿®å¤")
        
        # æ ‡è®°æœªè¦†ç›–çš„ç›®æ ‡é‡‡æ ·å™¨
        covered_targets = {r.target_pos for r in results if r.target_pos is not None}
        for t_idx, t_sampler in enumerate(target.samplers):
            if t_idx not in covered_targets and t_sampler.has_path:
                warnings.append(f"ç›®æ ‡é‡‡æ ·å™¨ #{t_idx} ({t_sampler.base_type}) æœªè¢«è¦†ç›–")
        
        return ReplaceResult(
            source_material=source,
            target_material=target,
            results=results,
            warnings=warnings,
            order_adjustments_count=self._adjustment_count,
            global_repair_triggered=False,
        )
    
    def _replace_legacy(
        self,
        source: Material,
        target: Material,
        source_legacy_samplers: List[Sampler],
        target_has_modern: bool,
    ) -> ReplaceResult:
        """
        ç‹¬ç«‹çš„æ—§ç‰ˆé‡‡æ ·å™¨åŒ¹é…é€»è¾‘
        
        åŒ¹é…ç­–ç•¥ï¼ˆç‹¬ç«‹äºæ ¸å¿ƒæœºåˆ¶ï¼‰ï¼š
        1. æ—§ç‰ˆâ†’æ—§ç‰ˆï¼šåŸºäºé‡‡æ ·å™¨åç§°ï¼ˆbase_typeï¼‰å®Œå…¨åŒ¹é…
        2. æ—§ç‰ˆâ†’æ–°ç‰ˆï¼šä½¿ç”¨è·¨ä¸–ä»£æ˜ å°„è¡¨è‡ªåŠ¨è½¬æ¢
        
        æºæè´¨æŒ‰åŸå§‹é¡ºåºéå†ï¼ˆæ— éœ€æ’åºï¼Œæ—§ç‰ˆæ²¡æœ‰ Indexï¼‰
        ç›®æ ‡æè´¨æŒ‰ Index æ’åºåéå†
        """
        from .sampler_type_parser import get_modern_mapping
        
        warnings: List[str] = []
        results: List[MatchResult] = []
        
        # ç›®æ ‡æè´¨æŒ‰ Index æ’åºï¼ˆæ–°ç‰ˆç›®æ ‡éœ€è¦ï¼‰
        indexed_target = list(enumerate(target.samplers))
        sorted_target = sorted(indexed_target, key=lambda x: (x[1].index, x[0]))
        
        # å·²å ç”¨çš„ç›®æ ‡ä½ç½®
        occupied_targets: set = set()
        
        self._log_lines.append(f"[Legacy Replace] Processing {len(source_legacy_samplers)} legacy source samplers")
        
        # è°ƒè¯•ï¼šè¾“å‡ºç›®æ ‡é‡‡æ ·å™¨ä¿¡æ¯
        self._log_lines.append(f"[Legacy Debug] Target samplers:")
        for idx, t_sampler in enumerate(target.samplers):
            self._log_lines.append(f"  [{idx}] index={t_sampler.index}, base_type='{t_sampler.base_type}', is_legacy={t_sampler.is_legacy}, has_path={t_sampler.has_path}")
        
        # éå†æ‰€æœ‰æºé‡‡æ ·å™¨ï¼ˆæŒ‰åŸå§‹é¡ºåºï¼‰
        for src_pos, src_sampler in enumerate(source.samplers):
            if not src_sampler.has_path:
                # æ— è·¯å¾„çš„æºé‡‡æ ·å™¨ï¼Œæ ‡è®°ä¸º EMPTY
                results.append(MatchResult(
                    source_pos=src_pos,
                    target_pos=None,
                    status=MatchStatus.EMPTY,
                    reason="æºé‡‡æ ·å™¨æ— è·¯å¾„ï¼Œè·³è¿‡åŒ¹é…",
                ))
                continue
            
            if not src_sampler.is_legacy:
                # éæ—§ç‰ˆæºé‡‡æ ·å™¨ï¼ˆç†è®ºä¸Šä¸åº”è¯¥åˆ°è¿™é‡Œï¼Œä½†åšä¿æŠ¤ï¼‰
                results.append(MatchResult(
                    source_pos=src_pos,
                    target_pos=None,
                    status=MatchStatus.UNMATCHED,
                    reason="éæ—§ç‰ˆé‡‡æ ·å™¨ï¼Œè·³è¿‡æ—§ç‰ˆåŒ¹é…é€»è¾‘",
                ))
                continue
            
            src_base_type = src_sampler.base_type
            matched_target_pos: Optional[int] = None
            match_status = MatchStatus.UNMATCHED
            match_reason = ""
            
            # === ç­–ç•¥1ï¼šæ—§ç‰ˆâ†’æ—§ç‰ˆ åç§°å®Œå…¨åŒ¹é… ===
            for orig_t_pos, t_sampler in sorted_target:
                if orig_t_pos in occupied_targets:
                    continue
                if t_sampler.is_legacy and t_sampler.base_type == src_base_type:
                    matched_target_pos = orig_t_pos
                    match_status = MatchStatus.PERFECT_MATCH
                    match_reason = f"æ—§ç‰ˆåç§°åŒ¹é…ï¼š{src_base_type}"
                    self._log_lines.append(f"[Legacy] Src[{src_pos}] {src_base_type} â†’ Target[{orig_t_pos}] (åç§°åŒ¹é…)")
                    break
            
            # === ç­–ç•¥2ï¼šæ—§ç‰ˆâ†’æ–°ç‰ˆ è·¨ä¸–ä»£æ˜ å°„ ===
            if matched_target_pos is None and target_has_modern:
                modern_types = get_modern_mapping(src_base_type)
                if modern_types:
                    self._log_lines.append(f"[Legacy] Trying cross-gen mapping: {src_base_type} â†’ {modern_types}")
                    
                    # éå†ç›®æ ‡ï¼ˆæŒ‰ Index æ’åºï¼‰ï¼Œæ‰¾ç¬¬ä¸€ä¸ªåŒ¹é…çš„ç°ä»£ç±»å‹
                    for modern_type in modern_types:
                        if matched_target_pos is not None:
                            break  # å·²æ‰¾åˆ°åŒ¹é…ï¼Œåœæ­¢
                        
                        for orig_t_pos, t_sampler in sorted_target:
                            if orig_t_pos in occupied_targets:
                                continue
                            if not t_sampler.is_legacy and t_sampler.base_type == modern_type:
                                matched_target_pos = orig_t_pos
                                match_status = MatchStatus.ADJACENT_MATCH  # è·¨ä¸–ä»£ç”¨é»„è‰²æ ‡è®°
                                match_reason = f"è·¨ä¸–ä»£æ˜ å°„ï¼š{src_base_type} â†’ {modern_type}"
                                self._log_lines.append(f"[Legacy] Src[{src_pos}] {src_base_type} â†’ Target[{orig_t_pos}] #{t_sampler.index} {modern_type} (è·¨ä¸–ä»£)")
                                break
            
            # è®°å½•åŒ¹é…ç»“æœ
            if matched_target_pos is not None:
                occupied_targets.add(matched_target_pos)
                results.append(MatchResult(
                    source_pos=src_pos,
                    target_pos=matched_target_pos,
                    status=match_status,
                    reason=match_reason,
                ))
            else:
                results.append(MatchResult(
                    source_pos=src_pos,
                    target_pos=None,
                    status=MatchStatus.UNMATCHED,
                    reason=f"æ—§ç‰ˆé‡‡æ ·å™¨ {src_base_type} æœªæ‰¾åˆ°åŒ¹é…ç›®æ ‡",
                ))
                warnings.append(f"æºé‡‡æ ·å™¨ {src_base_type} æœªåŒ¹é…")
        
        # æ ‡è®°æœªè¦†ç›–çš„ç›®æ ‡é‡‡æ ·å™¨
        for t_idx, t_sampler in enumerate(target.samplers):
            if t_idx not in occupied_targets and t_sampler.has_path:
                warnings.append(f"ç›®æ ‡é‡‡æ ·å™¨ #{t_idx} ({t_sampler.base_type}) æœªè¢«è¦†ç›–")
        
        return ReplaceResult(
            source_material=source,
            target_material=target,
            results=results,
            warnings=warnings,
            order_adjustments_count=0,
            global_repair_triggered=False,
        )
    
    def _match_single_sampler(
        self,
        sorted_src_idx: int,
        orig_src_pos: int,
        src_sampler: Sampler,
        sorted_target: List[Tuple[int, Sampler]],
        occupied: List[bool],
        match_of_target: Dict[int, int],
    ) -> MatchResult:
        """
        ä¸‰æ­¥åŒ¹é…ç­–ç•¥ï¼ˆä»å¤´æœç´¢ï¼Œæ—  cursorï¼‰
        
        Step 1: å®Œç¾åŒ¹é…ï¼ˆIndex + Type ç›¸åŒï¼‰
        Step 2: æ ‡è®°è¦†ç›–ï¼ˆåŒç±»å‹ + æœ‰è·¯å¾„ï¼‰
        Step 3: ç±»å‹åŒ¹é…ï¼ˆåŒç±»å‹ä»»æ„å¯ç”¨ï¼‰
        
        é‡åˆ°å†²çªæ—¶è¿›å…¥ Phase 2 åŠ¨æ€è°ƒæ•´
        """
        base_type = src_sampler.base_type
        src_index = src_sampler.index
        
        # Step 1: å®Œç¾åŒ¹é…ï¼ˆä»å¤´æœç´¢ï¼‰
        if self.options.prefer_perfect_match:
            for t_sorted_idx, (orig_t_pos, t_sampler) in enumerate(sorted_target):
                if t_sampler.base_type == base_type and t_sampler.index == src_index:
                    if not occupied[t_sorted_idx]:
                        return MatchResult(
                            source_pos=orig_src_pos,
                            target_pos=t_sorted_idx,
                            status=MatchStatus.PERFECT_MATCH,
                            reason=f"å®Œç¾åŒ¹é…ï¼šç±»å‹ {base_type}ï¼Œåºå· {src_index}",
                        )
                    else:
                        # å†²çªï¼šç›®æ ‡å·²è¢«å ç”¨ï¼Œå°è¯•è§£å†³
                        conflict_result = self._resolve_conflict(
                            sorted_src_idx, orig_src_pos, src_sampler,
                            t_sorted_idx, sorted_target, occupied, match_of_target
                        )
                        if conflict_result:
                            return conflict_result
        
        # Step 2: æ ‡è®°è¦†ç›–ï¼ˆåŒç±»å‹ + æœ‰è·¯å¾„ï¼‰
        if self.options.prefer_marked_coverage:
            for t_sorted_idx, (orig_t_pos, t_sampler) in enumerate(sorted_target):
                if t_sampler.base_type == base_type and t_sampler.has_path:
                    if not occupied[t_sorted_idx]:
                        return MatchResult(
                            source_pos=orig_src_pos,
                            target_pos=t_sorted_idx,
                            status=MatchStatus.ADJACENT_MATCH,
                            reason=f"æ ‡è®°è¦†ç›–ï¼šç±»å‹ {base_type}ï¼Œè¦†ç›–åŸè·¯å¾„",
                        )
        
        # Step 3: ç±»å‹åŒ¹é…ï¼ˆåŒç±»å‹ä»»æ„å¯ç”¨ï¼‰
        for t_sorted_idx, (orig_t_pos, t_sampler) in enumerate(sorted_target):
            if t_sampler.base_type == base_type:
                if not occupied[t_sorted_idx]:
                    marker = "å¡«å……ç©ºä½" if not t_sampler.has_path else "ç±»å‹åŒ¹é…"
                    return MatchResult(
                        source_pos=orig_src_pos,
                        target_pos=t_sorted_idx,
                        status=MatchStatus.ADJACENT_MATCH,
                        reason=f"{marker}ï¼šç±»å‹ {base_type}ï¼ˆç›®æ ‡åºå· {t_sampler.index}ï¼‰",
                    )
        
        # === Phase 2: Step1/2/3 å…¨å¤±è´¥ï¼Œå°è¯•åŠ¨æ€è°ƒæ•´ ===
        if self.options.allow_order_adjustment and self._adjustment_count < self.options.max_order_adjustments:
            # ç­–ç•¥Aï¼šç›¸é‚»äº¤æ¢ - æ‰¾è¢«å ç”¨çš„åŒç±»å‹ç›®æ ‡ï¼Œè®©å ç”¨è€…ç§»åˆ°ç›¸é‚»ä½ç½®
            phase2_result = self._phase2_swap_neighbor(
                sorted_src_idx, orig_src_pos, src_sampler,
                sorted_target, occupied, match_of_target
            )
            if phase2_result:
                return phase2_result
            
            # ç­–ç•¥Bï¼šå‘åå¹³ç§» - åœ¨çª—å£å†…æ‰¾ç©ºä½å¹¶é¡ºå»¶
            phase2_result = self._phase2_shift_forward(
                sorted_src_idx, orig_src_pos, src_sampler,
                sorted_target, occupied, match_of_target
            )
            if phase2_result:
                return phase2_result
        
        # æ— å¯ç”¨ç›®æ ‡
        return MatchResult(
            source_pos=orig_src_pos,
            target_pos=None,
            status=MatchStatus.UNMATCHED,
            reason=f"æœªæ‰¾åˆ°ç±»å‹ {base_type} çš„å¯ç”¨ç›®æ ‡",
        )
    
    def _resolve_conflict(
        self,
        current_src_idx: int,
        orig_src_pos: int,
        src_sampler: Sampler,
        target_idx: int,
        sorted_target: List[Tuple[int, Sampler]],
        occupied: List[bool],
        match_of_target: Dict[int, int],
    ) -> Optional[MatchResult]:
        """
        Phase 2: å†²çªå¤„ç†
        
        å½“å®Œç¾åŒ¹é…çš„ç›®æ ‡å·²è¢«å ç”¨æ—¶ï¼Œå°è¯•è®©å·²å ç”¨è€…è®©ä½
        """
        if not self.options.allow_order_adjustment:
            return None
        
        if self._adjustment_count >= self.options.max_order_adjustments:
            return None
        
        existing_src_idx = match_of_target.get(target_idx)
        if existing_src_idx is None:
            return None
        
        base_type = src_sampler.base_type
        
        # ç­–ç•¥Aï¼šè®©å·²å ç”¨è€…æ‰¾æ›¿ä»£ç›®æ ‡
        for alt_idx, (orig_pos, t_sampler) in enumerate(sorted_target):
            if alt_idx == target_idx:
                continue
            if t_sampler.base_type == base_type and not occupied[alt_idx]:
                # å·²å ç”¨è€…å¯ä»¥ç§»åˆ° alt_idx
                # è®©ä½
                occupied[alt_idx] = True
                match_of_target[alt_idx] = existing_src_idx
                occupied[target_idx] = False
                del match_of_target[target_idx]
                
                self._adjustment_count += 1
                self._log_lines.append(
                    f"[Conflict] æº{existing_src_idx} è®©ä½åˆ° {alt_idx}ï¼Œæº{current_src_idx} å ç”¨ {target_idx}"
                )
                
                return MatchResult(
                    source_pos=orig_src_pos,
                    target_pos=target_idx,
                    status=MatchStatus.PERFECT_MATCH,
                    reason=f"å®Œç¾åŒ¹é…ï¼ˆå†²çªè§£å†³ï¼‰ï¼šç±»å‹ {base_type}ï¼Œåºå· {src_sampler.index}",
                    order_adjusted=True,
                )
        
        return None
    
    def _phase2_swap_neighbor(
        self,
        sorted_src_idx: int,
        orig_src_pos: int,
        src_sampler: Sampler,
        sorted_target: List[Tuple[int, Sampler]],
        occupied: List[bool],
        match_of_target: Dict[int, int],
    ) -> Optional[MatchResult]:
        """
        Phase 2 ç­–ç•¥Aï¼šç›¸é‚»äº¤æ¢
        
        æ‰¾è¢«å ç”¨çš„åŒç±»å‹ç›®æ ‡ï¼Œçœ‹å ç”¨è€…èƒ½å¦ç§»åˆ°ç›¸é‚»ä½ç½®
        """
        base_type = src_sampler.base_type
        
        for j, (orig_pos, t_sampler) in enumerate(sorted_target):
            if t_sampler.base_type != base_type:
                continue
            if not occupied[j]:
                continue  # æœªè¢«å ç”¨ï¼Œä¸éœ€è¦äº¤æ¢
            
            # j è¢«å ç”¨ï¼Œçœ‹ j+1 èƒ½å¦å®¹çº³è¢«å ç”¨è€…
            if j + 1 < len(sorted_target):
                next_orig_pos, next_sampler = sorted_target[j + 1]
                if next_sampler.base_type == base_type and not occupied[j + 1]:
                    # æ‰§è¡Œäº¤æ¢
                    prev_src = match_of_target[j]
                    match_of_target[j + 1] = prev_src
                    match_of_target[j] = sorted_src_idx
                    occupied[j + 1] = True
                    # occupied[j] ä¿æŒ True
                    
                    self._adjustment_count += 1
                    self._log_lines.append(
                        f"[Phase2-SwapNeighbor] æº{prev_src} ç§»è‡³ {j+1}ï¼Œæº{sorted_src_idx} å ç”¨ {j}"
                    )
                    
                    return MatchResult(
                        source_pos=orig_src_pos,
                        target_pos=j,
                        status=MatchStatus.ADJACENT_MATCH,
                        reason=f"ç›¸é‚»äº¤æ¢ï¼šç±»å‹ {base_type}ï¼Œå°†åŸå ç”¨è€…ç§»è‡³ {j+1}",
                        order_adjusted=True,
                        adjustment_detail=f"swap: src{prev_src}->t{j+1}, src{sorted_src_idx}->t{j}",
                    )
        
        return None
    
    def _phase2_shift_forward(
        self,
        sorted_src_idx: int,
        orig_src_pos: int,
        src_sampler: Sampler,
        sorted_target: List[Tuple[int, Sampler]],
        occupied: List[bool],
        match_of_target: Dict[int, int],
    ) -> Optional[MatchResult]:
        """
        Phase 2 ç­–ç•¥Bï¼šå‘åå¹³ç§»
        
        åœ¨æœ‰é™çª—å£å†…æ‰¾ç©ºä½ï¼Œå°è¯•é¡ºå»¶å·²åŒ¹é…é¡¹
        """
        base_type = src_sampler.base_type
        window = 3  # å¯é…ç½®çª—å£å¤§å°
        
        # æ‰¾ç¬¬ä¸€ä¸ªåŒç±»å‹çš„è¢«å ç”¨ä½ç½®
        for start_idx, (orig_pos, t_sampler) in enumerate(sorted_target):
            if t_sampler.base_type != base_type:
                continue
            if not occupied[start_idx]:
                continue  # å¦‚æœæ‰¾åˆ°ç©ºä½ï¼ŒStep3 åº”è¯¥å·²ç»åŒ¹é…äº†
            
            # åœ¨ [start_idx, start_idx+window] å†…å¯»æ‰¾ç©ºä½
            for k in range(start_idx + 1, min(start_idx + window + 1, len(sorted_target))):
                k_orig_pos, k_sampler = sorted_target[k]
                if k_sampler.base_type == base_type and not occupied[k]:
                    # æ‰¾åˆ°ç©ºä½ kï¼Œå¯ä»¥æŠŠ start_idx çš„å ç”¨è€…ç§»åˆ° k
                    prev_src = match_of_target[start_idx]
                    
                    # æ‰§è¡Œå¹³ç§»
                    match_of_target[k] = prev_src
                    occupied[k] = True
                    
                    match_of_target[start_idx] = sorted_src_idx
                    # occupied[start_idx] ä¿æŒ True
                    
                    self._adjustment_count += 1
                    self._log_lines.append(
                        f"[Phase2-ShiftForward] æº{prev_src} ç§»è‡³ {k}ï¼Œæº{sorted_src_idx} å ç”¨ {start_idx}"
                    )
                    
                    return MatchResult(
                        source_pos=orig_src_pos,
                        target_pos=start_idx,
                        status=MatchStatus.ADJACENT_MATCH,
                        reason=f"å‘åå¹³ç§»ï¼šç±»å‹ {base_type}ï¼Œçª—å£å†…é¡ºå»¶",
                        order_adjusted=True,
                        adjustment_detail=f"shift: src{prev_src}->t{k}, src{sorted_src_idx}->t{start_idx}",
                    )
        
        return None
    
    def _match_by_type(
        self,
        src_pos: int,
        src_sampler: Sampler,
        targets: List[Sampler],
        target_occupied: List[bool],
        target_by_type: Dict[str, List[Tuple[int, Sampler]]],
    ) -> MatchResult:
        """
        æŒ‰ç±»å‹åŒ¹é…é‡‡æ ·å™¨
        
        ä¼˜å…ˆçº§ï¼š
        1. å®Œç¾åŒ¹é…ï¼šåŒ Type ä¸”åŒ Indexï¼ˆä¼˜å…ˆé€‰æœ‰è·¯å¾„çš„ï¼‰
        2. ç±»å‹åŒ¹é…ï¼šåŒ Type ä½† Index ä¸åŒï¼ˆä¼˜å…ˆé€‰æœ‰è·¯å¾„çš„ï¼‰
        """
        base_type = src_sampler.base_type
        src_index = src_sampler.index
        
        # è·å–è¯¥ç±»å‹çš„æ‰€æœ‰ç›®æ ‡é‡‡æ ·å™¨
        candidates = target_by_type.get(base_type, [])
        
        if not candidates:
            return MatchResult(
                source_pos=src_pos,
                target_pos=None,
                status=MatchStatus.UNMATCHED,
                reason=f"ç›®æ ‡æè´¨ä¸­ä¸å­˜åœ¨ç±»å‹ {base_type}",
            )
        
        # Step 1: å°è¯•å®Œç¾åŒ¹é…ï¼ˆIndex + Type ç›¸åŒï¼‰
        for t_pos, t_sampler in candidates:
            if target_occupied[t_pos]:
                continue
            if t_sampler.index == src_index:
                return MatchResult(
                    source_pos=src_pos,
                    target_pos=t_pos,
                    status=MatchStatus.PERFECT_MATCH,
                    reason=f"å®Œç¾åŒ¹é…ï¼šç±»å‹ {base_type}ï¼Œåºå· {src_index}",
                )
        
        # Step 2: ç±»å‹åŒ¹é…ï¼ˆä¼˜å…ˆé€‰æœ‰åŸè·¯å¾„çš„ç›®æ ‡é‡‡æ ·å™¨ï¼Œæ–¹ä¾¿è¦†ç›–ï¼‰
        for t_pos, t_sampler in candidates:
            if target_occupied[t_pos]:
                continue
            if t_sampler.has_path:
                return MatchResult(
                    source_pos=src_pos,
                    target_pos=t_pos,
                    status=MatchStatus.ADJACENT_MATCH,
                    reason=f"ç±»å‹åŒ¹é…ï¼š{base_type}ï¼Œè¦†ç›–åŸè·¯å¾„ï¼ˆç›®æ ‡åºå· {t_sampler.index}ï¼‰",
                )
        
        # Step 3: ç±»å‹åŒ¹é…ï¼ˆä»»æ„å¯ç”¨ï¼‰
        for t_pos, t_sampler in candidates:
            if target_occupied[t_pos]:
                continue
            return MatchResult(
                source_pos=src_pos,
                target_pos=t_pos,
                status=MatchStatus.ADJACENT_MATCH,
                reason=f"ç±»å‹åŒ¹é…ï¼š{base_type}ï¼ˆç›®æ ‡åºå· {t_sampler.index}ï¼‰",
            )
        
        # è¯¥ç±»å‹çš„æ‰€æœ‰ç›®æ ‡é‡‡æ ·å™¨éƒ½è¢«å ç”¨
        return MatchResult(
            source_pos=src_pos,
            target_pos=None,
            status=MatchStatus.UNMATCHED,
            reason=f"ç±»å‹ {base_type} çš„æ‰€æœ‰ç›®æ ‡é‡‡æ ·å™¨å·²è¢«å ç”¨",
        )
    
    def get_log(self) -> List[str]:
        """è·å–æœ€è¿‘ä¸€æ¬¡æ›¿æ¢çš„æ—¥å¿—"""
        return getattr(self, '_log_lines', [])
        
        return None
    
    def _global_order_check_and_repair(
        self,
        sources: List[Sampler],
        targets: List[Sampler],
        results: List[MatchResult],
        occupied: List[bool],
        match_of_target: Dict[int, int],
    ) -> bool:
        """
        Phase 3: å…¨å±€é¡ºåºæ£€æŸ¥ä¸äºŒæ¬¡ä¿®å¤
        
        æ£€æŸ¥æ‰€æœ‰å·²åŒ¹é…ç»“æœæ˜¯å¦æ»¡è¶³æºé¡ºåºçº¦æŸ
        å‘ç°å†²çªæ—¶å°è¯•å±€éƒ¨äº¤æ¢ä¿®å¤
        """
        # æ”¶é›†å·²åŒ¹é…çš„ç»“æœï¼ˆç´¢å¼• -> ç»“æœï¼‰
        result_by_src = {r.source_pos: r for r in results if r.target_pos is not None}
        if len(result_by_src) < 2:
            return False
        
        # æŒ‰æºæ’åºä½ç½®æ’åº
        matched_sorted = sorted(result_by_src.items(), key=lambda x: sources[x[0]].sorted_pos)
        
        repair_count = 0
        max_repairs = 3
        repaired = True
        
        # è¿­ä»£ä¿®å¤ï¼Œç›´åˆ°æ— å†²çªæˆ–è¾¾åˆ°ä¸Šé™
        while repaired and repair_count < max_repairs:
            repaired = False
            
            for i in range(len(matched_sorted) - 1):
                src_i, result_i = matched_sorted[i]
                src_j, result_j = matched_sorted[i + 1]
                tgt_i = result_i.target_pos
                tgt_j = result_j.target_pos
                
                if tgt_i is None or tgt_j is None:
                    continue
                
                if tgt_i >= tgt_j:
                    # å‘ç°å†²çªï¼šsrc_i çš„ç›®æ ‡ä½ç½® >= src_j çš„ç›®æ ‡ä½ç½®
                    # å°è¯•äº¤æ¢ä¿®å¤
                    
                    # æ£€æŸ¥æ˜¯å¦å¯ä»¥äº¤æ¢ä¸¤è€…çš„ç›®æ ‡ä½ç½®
                    src_i_type = sources[src_i].base_type
                    src_j_type = sources[src_j].base_type
                    tgt_i_type = targets[tgt_i].base_type if tgt_i < len(targets) else ""
                    tgt_j_type = targets[tgt_j].base_type if tgt_j < len(targets) else ""
                    
                    # åªæœ‰ç±»å‹å…¼å®¹æ—¶æ‰èƒ½äº¤æ¢
                    if src_i_type == tgt_j_type and src_j_type == tgt_i_type:
                        # æ‰§è¡Œäº¤æ¢
                        result_i.target_pos = tgt_j
                        result_j.target_pos = tgt_i
                        result_i.order_adjusted = True
                        result_j.order_adjusted = True
                        result_i.adjustment_detail += " å…¨å±€é¡ºåºä¿®å¤(äº¤æ¢)"
                        result_j.adjustment_detail += " å…¨å±€é¡ºåºä¿®å¤(äº¤æ¢)"
                        
                        repair_count += 1
                        repaired = True
                        self._log_lines.append(
                            f"[Phase3-Repair] äº¤æ¢ src{src_i}->t{tgt_j}, src{src_j}->t{tgt_i}"
                        )
                        
                        # é‡æ–°æ’åºåç»§ç»­æ£€æŸ¥
                        matched_sorted = sorted(result_by_src.items(), 
                                                key=lambda x: sources[x[0]].sorted_pos)
                        break
                    else:
                        # æ— æ³•äº¤æ¢ï¼Œè®°å½•è­¦å‘Š
                        logger.warning(
                            f"é¡ºåºå†²çªæ— æ³•ä¿®å¤ï¼šæº {src_i}(pos={sources[src_i].sorted_pos}) -> ç›®æ ‡ {tgt_i}, "
                            f"ä½†æº {src_j}(pos={sources[src_j].sorted_pos}) -> ç›®æ ‡ {tgt_j}"
                        )
                        result_i.order_adjusted = True
                        result_j.order_adjusted = True
                        result_i.adjustment_detail += " é¡ºåºå†²çª(æ— æ³•ä¿®å¤)"
                        result_j.adjustment_detail += " é¡ºåºå†²çª(æ— æ³•ä¿®å¤)"
        
        return repair_count > 0


def apply_replacement(source: Material, target: Material, result: ReplaceResult) -> Material:
    """
    åº”ç”¨æ›¿æ¢ç»“æœï¼Œç”Ÿæˆæ–°çš„æè´¨æ•°æ®
    
    Args:
        source: æºæè´¨
        target: ç›®æ ‡æè´¨æ¨¡æ¿
        result: æ›¿æ¢ç»“æœ
    
    Returns:
        æ–°çš„æè´¨å¯¹è±¡ï¼ˆåŸºäºç›®æ ‡ç»“æ„ï¼Œå¡«å…¥æºè·¯å¾„ï¼‰
    """
    # æ·±æ‹·è´ç›®æ ‡æè´¨
    new_samplers = []
    for t_idx, t_sampler in enumerate(target.samplers):
        new_sampler = Sampler(
            type_name=t_sampler.type_name,
            path=t_sampler.path,  # é»˜è®¤ä¿ç•™ç›®æ ‡è·¯å¾„
            scale_x=t_sampler.scale_x,
            scale_y=t_sampler.scale_y,
            unk10=t_sampler.unk10,
            unk11=t_sampler.unk11,
            unk14=t_sampler.unk14,
            unk18=t_sampler.unk18,
            unk1c=t_sampler.unk1c,
            index=t_sampler.index,
            base_type=t_sampler.base_type,
            is_legacy=t_sampler.is_legacy,
            sorted_pos=t_idx,
        )
        new_samplers.append(new_sampler)
    
    # åº”ç”¨åŒ¹é…ç»“æœ
    for match_result in result.results:
        if match_result.target_pos is not None:
            src_sampler = source.samplers[match_result.source_pos]
            tgt_sampler = new_samplers[match_result.target_pos]
            
            # å¤åˆ¶è·¯å¾„å’Œå‚æ•°
            tgt_sampler.path = src_sampler.path
            tgt_sampler.scale_x = src_sampler.scale_x
            tgt_sampler.scale_y = src_sampler.scale_y
    
    return Material(
        name=source.name,
        mtd_path=target.mtd_path,
        samplers=new_samplers,
        gx_index=source.gx_index,
        index=source.index,
    )
