#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤šçº¿ç¨‹æè´¨åŒ¹é…å™¨ - è¶…é«˜æ€§èƒ½ç‰ˆæœ¬
"""

import threading
import queue
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Optional, Callable
from src.core.fast_material_matcher import FastMaterialMatcher


class MultiThreadMaterialMatcher(FastMaterialMatcher):
    """å¤šçº¿ç¨‹æè´¨åŒ¹é…å™¨"""
    
    def __init__(self, database_manager):
        super().__init__(database_manager)
        
        # å¤šçº¿ç¨‹é…ç½® - é«˜æ€§èƒ½ä¼˜åŒ–
        self.max_workers = 32  # å¢åŠ åˆ°32çº¿ç¨‹è¿›è¡Œè¶…é«˜é€Ÿå¤„ç†
        self.chunk_size = 150  # å‡å°‘å—å¤§å°ï¼Œå¢åŠ å¹¶è¡Œåº¦
        self.progress_callback = None
        self.stop_event = threading.Event()  # æ·»åŠ åœæ­¢äº‹ä»¶
        
        # ç²¾ç¡®åŒ¹é…ä¸ä½¿ç”¨é˜ˆå€¼boostï¼Œä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è®¾å®šçš„é˜ˆå€¼
        self.similarity_threshold_boost = 0.0
        
    def find_similar_materials_parallel(self, source_material: Dict, target_library_id: int, 
                                      priority_order: List[str], similarity_threshold: float,
                                      progress_callback: Optional[Callable] = None) -> List[Dict]:
        """
        å¹¶è¡ŒæŸ¥æ‰¾ç›¸ä¼¼æè´¨
        """
        try:
            self.progress_callback = progress_callback
            
            # è·å–ç›®æ ‡åº“ä¸­çš„æ‰€æœ‰æè´¨
            target_materials = self.database_manager.get_materials_by_library(target_library_id)
            
            # å¤šçº¿ç¨‹æ¨¡å¼ä¸å†é™åˆ¶æè´¨æ•°é‡ï¼Œå¤„ç†å…¨éƒ¨æè´¨
            
            # å¯åŠ¨å¤šçº¿ç¨‹æœç´¢ï¼ˆé™é»˜ï¼‰
            
            # è·å–æºæè´¨çš„è¯¦ç»†ä¿¡æ¯
            source_details = self._get_material_details(source_material)
            
            # ç²¾ç¡®åŒ¹é…åº”è¯¥æ ¹æ®ç”¨æˆ·é…ç½®çš„ä¼˜å…ˆçº§é¡ºåºè®¡ç®—æƒé‡
            weights = self._calculate_weights(priority_order)
            library_name = self._get_library_name(target_library_id)
            
            # å°†æè´¨åˆ†å—å¤„ç†
            chunks = self._split_into_chunks(target_materials, self.chunk_size)
            
            start_time = time.time()
            all_results = []
            processed_count = 0
            total_materials = len(target_materials)
            
            # é‡ç½®åœæ­¢äº‹ä»¶
            self.stop_event.clear()
            
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                # æäº¤æ‰€æœ‰ä»»åŠ¡
                future_to_chunk = {
                    executor.submit(
                        self._process_chunk,
                        chunk_id,
                        chunk,
                        source_material,
                        source_details,
                        weights,
                        library_name,
                        target_library_id,  # æ·»åŠ ç›®æ ‡åº“ID
                        similarity_threshold,
                        self.stop_event  # ä¼ é€’åœæ­¢äº‹ä»¶
                    ): (chunk_id, len(chunk))
                    for chunk_id, chunk in enumerate(chunks)
                }
                
                # æ”¶é›†ç»“æœ - ä¼˜åŒ–å¹¶å‘å¤„ç†
                completed_chunks = 0
                total_chunks = len(chunks)
                
                for future in as_completed(future_to_chunk):
                    # æ£€æŸ¥åœæ­¢ä¿¡å·
                    if self.stop_event.is_set():
                        print("ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œå–æ¶ˆå‰©ä½™ä»»åŠ¡")
                        # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
                        for pending_future in future_to_chunk:
                            if not pending_future.done():
                                pending_future.cancel()
                        break
                    
                    chunk_id, chunk_size = future_to_chunk[future]
                    try:
                        chunk_results = future.result(timeout=30)  # è®¾ç½®è¶…æ—¶
                        all_results.extend(chunk_results)
                        processed_count += chunk_size
                        completed_chunks += 1
                        
                        # æ›´æ–°è¿›åº¦ - æ”¯æŒGUIè¿›åº¦æ¡
                        if self.progress_callback:
                            progress = (processed_count / total_materials) * 100
                            self.progress_callback(progress)
                        
                        # å¤§å¹…å‡å°‘è¾“å‡ºé¢‘ç‡ - åªåœ¨å®Œæˆæ—¶è¾“å‡º
                        if completed_chunks == total_chunks:
                            print(f"âœ… æ‰€æœ‰çº¿ç¨‹å®Œæˆï¼Œæ€»è®¡æ‰¾åˆ° {len(all_results)} ä¸ªç»“æœ")
                            
                    except Exception as e:
                        # é™é»˜å¤„ç†é”™è¯¯ï¼Œä¸è¾“å‡ºåˆ°æ§åˆ¶å°
                        continue
            
            # è¶…é«˜é€Ÿæ’åº - ç§»é™¤è¾“å‡ºï¼Œç›´æ¥æ’åº
            if all_results:
                # å¯¹äºå¤§é‡ç»“æœï¼Œä½¿ç”¨å¹¶è¡Œæ’åºä¼˜åŒ–
                if len(all_results) > 1000:
                    # åˆ†å—æ’åºååˆå¹¶ï¼ˆé€‚åˆå¤§æ•°æ®é›†ï¼‰
                    chunk_size = len(all_results) // 4
                    chunks = [all_results[i:i + chunk_size] for i in range(0, len(all_results), chunk_size)]
                    
                    with ThreadPoolExecutor(max_workers=4) as sort_executor:
                        sorted_chunks = list(sort_executor.map(
                            lambda chunk: sorted(chunk, key=lambda x: x['similarity'], reverse=True), 
                            chunks
                        ))
                    
                    # åˆå¹¶å·²æ’åºçš„å—
                    import heapq
                    all_results = list(heapq.merge(*sorted_chunks, key=lambda x: x['similarity'], reverse=True))
                else:
                    # å°æ•°æ®é›†ç›´æ¥æ’åº
                    all_results.sort(key=lambda x: x['similarity'], reverse=True)
            
            results = all_results  # è¿”å›æ‰€æœ‰ç¬¦åˆé˜ˆå€¼çš„ç»“æœ
            
            elapsed = time.time() - start_time
            print(f"å¹¶è¡ŒåŒ¹é…å®Œæˆ: å¤„ç†äº†{processed_count}ä¸ªæè´¨ï¼Œæ‰¾åˆ°{len(results)}ä¸ªåŒ¹é…ç»“æœï¼Œè€—æ—¶{elapsed:.1f}ç§’")
            print(f"å¹³å‡é€Ÿåº¦: {processed_count/elapsed:.0f} æè´¨/ç§’")
            
            return results
            
        except Exception as e:
            raise Exception(f"å¹¶è¡Œæè´¨åŒ¹é…å¤±è´¥: {str(e)}")
    
    def _split_into_chunks(self, materials: List[Dict], chunk_size: int) -> List[List[Dict]]:
        """å°†æè´¨åˆ—è¡¨åˆ†å‰²æˆå—"""
        chunks = []
        for i in range(0, len(materials), chunk_size):
            chunks.append(materials[i:i + chunk_size])
        return chunks
    
    def _process_chunk(self, chunk_id: int, chunk: List[Dict], source_material: Dict,
                      source_details: Dict, weights: Dict, library_name: str,
                      target_library_id: int, similarity_threshold: float, 
                      stop_event: threading.Event = None) -> List[Dict]:
        """å¤„ç†ä¸€ä¸ªæè´¨å—"""
        results = []
        
        try:
            for i, target_material in enumerate(chunk):
                # æ£€æŸ¥åœæ­¢ä¿¡å·ï¼ˆæ¯10ä¸ªæè´¨æ£€æŸ¥ä¸€æ¬¡ï¼Œå‡å°‘å¼€é”€ï¼‰
                if stop_event and i % 10 == 0 and stop_event.is_set():
                    print(f"ğŸ›‘ çº¿ç¨‹ {chunk_id} æ”¶åˆ°åœæ­¢ä¿¡å·")
                    break
                
                try:
                    # è·³è¿‡åŒä¸€ä¸ªæè´¨
                    if (source_material.get('id') == target_material.get('id') and 
                        source_material.get('library_id') == target_material.get('library_id')):
                        continue
                    
                    # ç²¾ç¡®åŒ¹é…ä¸ä½¿ç”¨é¢„ç­›é€‰ï¼Œè¿›è¡Œå…¨å‚æ•°åŒ¹é…
                    # ç§»é™¤é¢„ç­›é€‰ï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•å¯èƒ½çš„åŒ¹é…
                    
                    # è®¡ç®—è¯¦ç»†ç›¸ä¼¼åº¦
                    similarity_info = self._calculate_similarity_optimized(
                        source_details, 
                        target_material, 
                        weights
                    )
                    
                    total_similarity = similarity_info['total']
                    
                    # é™é»˜å¤„ç†
                    
                    # æ£€æŸ¥æ˜¯å¦æ»¡è¶³é˜ˆå€¼
                    if total_similarity >= similarity_threshold:
                        # è·å–ç›®æ ‡æè´¨è¯¦æƒ…ç”¨äºè®¡ç®—æ•°é‡
                        target_details = self._get_material_details(target_material)
                        
                        # å°†é‡‡æ ·å™¨/å‚æ•°ä¿¡æ¯æ·»åŠ åˆ°è¯¦æƒ…ä¸­ï¼Œä¾¿äºUIæ˜¾ç¤º
                        details = similarity_info['details'].copy()
                        details['source_sampler_count'] = len(source_details.get('samplers', []))
                        details['target_sampler_count'] = len(target_details.get('samplers', []))
                        details['source_param_count'] = len(source_details.get('parameters', []))
                        details['target_param_count'] = len(target_details.get('parameters', []))
                        
                        results.append({
                            'material': target_material,
                            'similarity': total_similarity,
                            'details': details,
                            'library_name': library_name,
                            'target_library_id': target_library_id,  # æ·»åŠ ç›®æ ‡åº“IDç”¨äºè·³è½¬
                            'source_material': source_material,  # æ·»åŠ æºæè´¨ä¿¡æ¯
                            'target_material': target_material   # æ·»åŠ ç›®æ ‡æè´¨ä¿¡æ¯ï¼ˆä¸ºäº†ç»Ÿä¸€ï¼‰
                        })
                        
                        # å¦‚æœè¿™ä¸ªå—å·²ç»æ‰¾åˆ°è¶³å¤Ÿçš„ç»“æœï¼Œåœæ­¢å¤„ç†
                        if len(results) >= self.max_results_per_search // self.max_workers:
                            break
                        
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"å¤„ç†å— {chunk_id} æ—¶å‡ºé”™: {e}")
        
        return results
    
    def stop_matching(self):
        """åœæ­¢å½“å‰åŒ¹é…è¿›ç¨‹"""
        if hasattr(self, 'stop_event'):
            self.stop_event.set()
            print("ğŸ›‘ å¤šçº¿ç¨‹åŒ¹é…å·²è¯·æ±‚åœæ­¢")


class AsyncMaterialMatcher:
    """å¼‚æ­¥æè´¨åŒ¹é…å™¨ - ç”¨äºGUI"""
    
    def __init__(self, database_manager):
        self.matcher = MultiThreadMaterialMatcher(database_manager)
        self.stop_event = threading.Event()
        self.current_thread = None
        
    def start_matching(self, source_material: Dict, target_library_id: int,
                      priority_order: List[str], similarity_threshold: float,
                      progress_callback: Optional[Callable] = None,
                      completion_callback: Optional[Callable] = None):
        """å¯åŠ¨å¼‚æ­¥åŒ¹é…"""
        # åœæ­¢ä¹‹å‰çš„åŒ¹é…
        self.stop_matching()
        
        # é‡ç½®åœæ­¢äº‹ä»¶
        self.stop_event.clear()
        
        # å¯åŠ¨æ–°çš„åŒ¹é…çº¿ç¨‹
        self.current_thread = threading.Thread(
            target=self._run_matching,
            args=(source_material, target_library_id, priority_order, 
                  similarity_threshold, progress_callback, completion_callback),
            daemon=True
        )
        self.current_thread.start()
        
    def stop_matching(self):
        """åœæ­¢å½“å‰åŒ¹é…"""
        if self.current_thread and self.current_thread.is_alive():
            self.stop_event.set()
            self.current_thread.join(timeout=1.0)
            
    def _run_matching(self, source_material: Dict, target_library_id: int,
                     priority_order: List[str], similarity_threshold: float,
                     progress_callback: Optional[Callable] = None,
                     completion_callback: Optional[Callable] = None):
        """è¿è¡ŒåŒ¹é…ä»»åŠ¡"""
        try:
            # åŒ…è£…è¿›åº¦å›è°ƒä»¥æ£€æŸ¥åœæ­¢äº‹ä»¶
            def wrapped_progress_callback(progress, processed, total):
                if self.stop_event.is_set():
                    raise InterruptedError("åŒ¹é…è¢«ç”¨æˆ·å–æ¶ˆ")
                if progress_callback:
                    progress_callback(progress, processed, total)
            
            results = self.matcher.find_similar_materials_parallel(
                source_material, target_library_id, priority_order, 
                similarity_threshold, wrapped_progress_callback
            )
            
            if not self.stop_event.is_set() and completion_callback:
                completion_callback(results, None)
                
        except InterruptedError as e:
            print(f"åŒ¹é…è¢«ä¸­æ–­: {e}")
            if completion_callback:
                completion_callback([], str(e))
        except Exception as e:
            print(f"åŒ¹é…å¤±è´¥: {e}")
            if completion_callback:
                completion_callback([], str(e))

    def find_similar_materials_multi_thread(self, source_material: Dict, target_library_id: int, 
                                           priority_order: List[str], similarity_threshold: float,
                                           skip_prefilter: bool = False) -> List[Dict]:
        """
        å¤šçº¿ç¨‹æœç´¢çš„åŒæ­¥æ¥å£ï¼Œæ”¯æŒè·³è¿‡é¢„ç­›é€‰
        """
        if skip_prefilter:
            print("å¤šçº¿ç¨‹ç²¾ç¡®æœç´¢ - è·³è¿‡æ‰€æœ‰é¢„ç­›é€‰")
            # ä¸´æ—¶ä¿®æ”¹é¢„ç­›é€‰è®¾ç½®
            original_method = self._strict_prefilter
            self._strict_prefilter = lambda *args: True  # è·³è¿‡é¢„ç­›é€‰
            
        try:
            result = self.find_similar_materials_parallel(
                source_material, target_library_id, priority_order, similarity_threshold
            )
            return result
        finally:
            if skip_prefilter:
                # æ¢å¤åŸæ¥çš„é¢„ç­›é€‰æ–¹æ³•
                self._strict_prefilter = original_method


# åˆ›å»ºåˆ«åä»¥ä¿æŒå‘åå…¼å®¹
MultiThreadMatcher = MultiThreadMaterialMatcher